{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lstm-text-generator.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rawar/tensorflow-notebooks/blob/master/lstm_text_generator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6OYiIvNaLpaQ",
        "colab_type": "text"
      },
      "source": [
        "## Textgenerator based on news\n",
        "\n",
        "Based on Enriques work of an [Word-level LSTM text generator](https://medium.com/coinmonks/word-level-lstm-text-generator-creating-automatic-song-lyrics-with-neural-networks-b8a1617104fb)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fAfKbq7RLj5a",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        },
        "outputId": "097728d1-7773-40ef-b61c-985cf9a6bcf8"
      },
      "source": [
        "!pip install tf-nightly-gpu"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tf-nightly-gpu in /usr/local/lib/python3.6/dist-packages (1.14.1.dev20190512)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-gpu) (0.33.1)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-gpu) (0.7.1)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-gpu) (1.11.1)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-gpu) (0.2.2)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-gpu) (0.1.6)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-gpu) (1.1.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-gpu) (1.16.3)\n",
            "Requirement already satisfied: tb-nightly<1.15.0a0,>=1.14.0a0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-gpu) (1.14.0a20190512)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-gpu) (1.15.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-gpu) (1.0.9)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-gpu) (0.7.1)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-gpu) (1.12.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-gpu) (1.0.7)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-gpu) (3.7.1)\n",
            "Requirement already satisfied: tf-estimator-nightly in /usr/local/lib/python3.6/dist-packages (from tf-nightly-gpu) (1.14.0.dev2019051201)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.15.0a0,>=1.14.0a0->tf-nightly-gpu) (3.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.15.0a0,>=1.14.0a0->tf-nightly-gpu) (0.15.2)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tf-nightly-gpu) (2.8.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tf-nightly-gpu) (41.0.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QGDnESfOL59u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8KV-7cgQL9cC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "url = 'https://gist.githubusercontent.com/rawar/ae4cce269e29c2826163fbca60b544f4/raw/20594a832b44de4b4a5160fb2732399ba09a70e9/reco-content-data.csv'\n",
        "text_corpus = pd.read_csv(url)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "isKcV3P-N1_M",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        },
        "outputId": "2dcbd005-5672-461d-8365-a34b95727df8"
      },
      "source": [
        "headlines_data_frame = text_corpus['title']\n",
        "headlines_data_frame = headlines_data_frame.dropna()\n",
        "headlines_data_frame.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0                             Google verkauft Motorola\n",
              "1    Touchscreen im Winter: Handy-Handschuhe selber...\n",
              "2    \\Bei WhatsApp als Kontakt blockiert: So merkt ...\n",
              "3    Paper: Facebook stellt neue App im Flipboard-S...\n",
              "4               WhatsApp: mehr Privatsphäre für Nutzer\n",
              "Name: title, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HjoBmqq6ObR2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cc483972-1b8c-4332-f15e-7e169de82e43"
      },
      "source": [
        "text_in_words = headlines_data_frame.str.split(' ').tolist()\n",
        "print('Number of sentences:', len(text_in_words))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of sentences: 15751\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w2SedEtPRKn1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "72d2d171-a022-444f-8e60-48dcc3d23ab4"
      },
      "source": [
        "print(text_in_words[15749:15750])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['Fatburner-Training:', 'Diese', 'Übungen', 'sind', 'für', 'Männer']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RwEf2UuQ8nn1",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S-ahG-H7WWEy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "dcf444c0-0a0a-408d-b757-c48e2964095f"
      },
      "source": [
        "MAX_WORDS_PER_HEADLINE = 5\n",
        "for example in text_in_words:\n",
        "  new_max = len(example)\n",
        "  if new_max > MAX_WORDS_PER_HEADLINE:\n",
        "    MAX_WORDS_PER_HEADLINE = new_max\n",
        "    \n",
        "print(MAX_WORDS_PER_HEADLINE)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "16\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "spfLX9jrptps",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "words = set()\n",
        "for sentence in text_in_words:\n",
        "  for word in sentence:\n",
        "    words.add(word)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n0FZGXikqDdg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0583814c-148f-41cb-afcf-9a5f9d251b00"
      },
      "source": [
        "len(words)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10654"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HktnI8lEszSd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "word_indices = dict((c, i) for i, c in enumerate(words))\n",
        "indices_word = dict((i, c) for i, c in enumerate(words))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IwSVSVf6W2rI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "SEQUENCE_LEN = 2\n",
        "MIN_WORD_FREQUENCY = 1\n",
        "STEP = 1\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 50"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TFcXCVdfeULj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentences = []\n",
        "next_words = []\n",
        "ignored = 0\n",
        "for sentence in text_in_words:\n",
        "  for i in range(0, len(sentence) - SEQUENCE_LEN, STEP):\n",
        "    sentences.append(sentence[i:i + SEQUENCE_LEN])\n",
        "    next_words.append(sentence[i + SEQUENCE_LEN])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bpV0b6qlgIGA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#print(sentences[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vCA78RmVhIza",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#print(next_words[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QkJgWu4Mggsx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#print(sentences[2])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "69Y8tXc7gm3L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#print(next_words[2])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iE5wwTTLXsT1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def shuffle_and_split_training_set(sentences_original, next_original, percentage_test=2):\n",
        "    # shuffle at unison\n",
        "    print('Shuffling sentences')\n",
        "\n",
        "    tmp_sentences = []\n",
        "    tmp_next_word = []\n",
        "    for i in np.random.permutation(len(sentences_original)):\n",
        "        tmp_sentences.append(sentences_original[i])\n",
        "        tmp_next_word.append(next_original[i])\n",
        "\n",
        "    cut_index = int(len(sentences_original) * (1.-(percentage_test/100.)))\n",
        "    x_train, x_test = tmp_sentences[:cut_index], tmp_sentences[cut_index:]\n",
        "    y_train, y_test = tmp_next_word[:cut_index], tmp_next_word[cut_index:]\n",
        "\n",
        "    print(\"Size of training set = %d\" % len(x_train))\n",
        "    print(\"Size of test set = %d\" % len(y_test))\n",
        "    return (x_train, y_train), (x_test, y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G57ukcEakHaY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "c150c5fa-a963-458a-c762-14e5c7db60c7"
      },
      "source": [
        "(sentences_train, next_words_train), (sentences_test, next_words_test) = shuffle_and_split_training_set(sentences, next_words)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shuffling sentences\n",
            "Size of training set = 98214\n",
            "Size of test set = 2005\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wQUYiObqlsN0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "outputId": "48af95fd-01c0-4ee4-ef5e-b7ad757bfc3a"
      },
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Embedding(input_dim=len(words), output_dim=1024),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(units=128)),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.Dense(len(words)),\n",
        "    tf.keras.layers.Activation('softmax')\n",
        "])"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0512 16:55:54.995031 139959589132160 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/initializers.py:119: calling RandomUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "W0512 16:55:54.998946 139959589132160 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "W0512 16:55:55.007711 139959589132160 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "W0512 16:55:55.008885 139959589132160 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:97: calling Orthogonal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "W0512 16:55:55.009995 139959589132160 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M8KqMMscqgXW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generator(sentence_list, next_word_list, batch_size):\n",
        "    index = 0\n",
        "    while True:\n",
        "        x = np.zeros((batch_size, SEQUENCE_LEN), dtype=np.int32)\n",
        "        y = np.zeros((batch_size), dtype=np.int32)\n",
        "        for i in range(batch_size):\n",
        "            for t, w in enumerate(sentence_list[index % len(sentence_list)]):\n",
        "                x[i, t] = word_indices[w]\n",
        "            y[i] = word_indices[next_word_list[index % len(sentence_list)]]\n",
        "            index = index + 1\n",
        "        yield x, y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dvN-MvovrFep",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss='sparse_categorical_crossentropy', optimizer=\"adam\", metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xP3ek5GpsaxR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6a3e44a6-6f7b-4d08-f3bd-a252c7164948"
      },
      "source": [
        "!mkdir checkpoints"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘checkpoints’: File exists\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dkogyqHsrP69",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "file_path = \"./checkpoints/lstm-text-gen-epoch{epoch:03d}-words%d-sequence%d-minfreq%d-\" \\\n",
        "                \"loss{loss:.4f}-acc{acc:.4f}-val_loss{val_loss:.4f}-val_acc{val_acc:.4f}\" % \\\n",
        "                (len(words), SEQUENCE_LEN, MIN_WORD_FREQUENCY)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fBpA9iQjt1vq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sample(preds, temperature=1.0):\n",
        "    # helper function to sample an index from a probability array\n",
        "    preds = np.asarray(preds).astype('float64')\n",
        "    preds = np.log(preds) / temperature\n",
        "    exp_preds = np.exp(preds)\n",
        "    preds = exp_preds / np.sum(exp_preds)\n",
        "    probas = np.random.multinomial(1, preds, 1)\n",
        "    return np.argmax(probas)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G2wXHE9qrWx3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def on_epoch_end(epoch, logs):\n",
        "    # Function invoked at end of each epoch. Prints generated text.\n",
        "    examples_file.write('\\n----- Generating text after Epoch: %d\\n' % epoch)\n",
        "\n",
        "    # Randomly pick a seed sequence\n",
        "    seed_index = np.random.randint(len(sentences+sentences_test))\n",
        "    seed = (sentences+sentences_test)[seed_index]\n",
        "\n",
        "    for diversity in [0.3, 0.4, 0.5, 0.6, 0.7]:\n",
        "        sentence = seed\n",
        "        examples_file.write('----- Diversity:' + str(diversity) + '\\n')\n",
        "        examples_file.write('----- Generating with seed:\\n\"' + ' '.join(sentence) + '\"\\n')\n",
        "        examples_file.write(' '.join(sentence))\n",
        "\n",
        "        for i in range(MAX_WORDS_PER_HEADLINE):\n",
        "            x_pred = np.zeros((1, SEQUENCE_LEN))\n",
        "            for t, word in enumerate(sentence):\n",
        "                x_pred[0, t] = word_indices[word]\n",
        "\n",
        "            preds = model.predict(x_pred, verbose=0)[0]\n",
        "            next_index = sample(preds, diversity)\n",
        "            next_word = indices_word[next_index]\n",
        "\n",
        "            sentence = sentence[1:]\n",
        "            sentence.append(next_word)\n",
        "\n",
        "            examples_file.write(\" \"+next_word)\n",
        "        examples_file.write('\\n')\n",
        "    examples_file.write('='*80 + '\\n')\n",
        "    examples_file.flush()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t3EW8J5jreRl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "checkpoint = tf.keras.callbacks.ModelCheckpoint(file_path, monitor='val_acc', save_best_only=True)\n",
        "print_callback = tf.keras.callbacks.LambdaCallback(on_epoch_end=on_epoch_end)\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_acc', patience=20)\n",
        "callbacks_list = [checkpoint, print_callback, early_stopping]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uWiB4lP_tZ8F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "examples_file = open('examples.txt', \"w\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GjRNhXT9r0jp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1193
        },
        "outputId": "2e083aa1-f5c7-46d3-fd52-48417f4e8e9a"
      },
      "source": [
        "history = model.fit_generator(generator(sentences, next_words, BATCH_SIZE),\n",
        "                    steps_per_epoch=int(len(sentences)/BATCH_SIZE) + 1,\n",
        "                    epochs=EPOCHS,\n",
        "                    callbacks=callbacks_list,\n",
        "                    validation_data=generator(sentences_test, next_words_test, BATCH_SIZE),\n",
        "                    validation_steps=int(len(sentences_test)/BATCH_SIZE) + 1)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "3132/3132 [==============================] - 44s 14ms/step - loss: 0.9769 - acc: 0.8010 - val_loss: 0.8297 - val_acc: 0.8224\n",
            "Epoch 2/50\n",
            "3132/3132 [==============================] - 45s 14ms/step - loss: 0.8271 - acc: 0.8195 - val_loss: 0.6810 - val_acc: 0.8472\n",
            "Epoch 3/50\n",
            "3132/3132 [==============================] - 45s 14ms/step - loss: 0.7276 - acc: 0.8333 - val_loss: 0.5945 - val_acc: 0.8591\n",
            "Epoch 4/50\n",
            "3132/3132 [==============================] - 45s 14ms/step - loss: 0.6726 - acc: 0.8410 - val_loss: 0.5360 - val_acc: 0.8681\n",
            "Epoch 5/50\n",
            "3132/3132 [==============================] - 46s 15ms/step - loss: 0.6427 - acc: 0.8456 - val_loss: 0.5271 - val_acc: 0.8686\n",
            "Epoch 6/50\n",
            "3132/3132 [==============================] - 44s 14ms/step - loss: 0.6192 - acc: 0.8491 - val_loss: 0.4922 - val_acc: 0.8780\n",
            "Epoch 7/50\n",
            "3132/3132 [==============================] - 45s 14ms/step - loss: 0.6060 - acc: 0.8499 - val_loss: 0.4728 - val_acc: 0.8745\n",
            "Epoch 8/50\n",
            "3132/3132 [==============================] - 44s 14ms/step - loss: 0.5929 - acc: 0.8513 - val_loss: 0.4511 - val_acc: 0.8710\n",
            "Epoch 9/50\n",
            "3132/3132 [==============================] - 45s 14ms/step - loss: 0.5800 - acc: 0.8522 - val_loss: 0.4405 - val_acc: 0.8740\n",
            "Epoch 10/50\n",
            "3132/3132 [==============================] - 45s 14ms/step - loss: 0.5752 - acc: 0.8531 - val_loss: 0.4340 - val_acc: 0.8810\n",
            "Epoch 11/50\n",
            "3132/3132 [==============================] - 45s 14ms/step - loss: 0.5650 - acc: 0.8529 - val_loss: 0.4203 - val_acc: 0.8780\n",
            "Epoch 12/50\n",
            "3132/3132 [==============================] - 45s 15ms/step - loss: 0.5584 - acc: 0.8544 - val_loss: 0.4301 - val_acc: 0.8780\n",
            "Epoch 13/50\n",
            "3132/3132 [==============================] - 45s 14ms/step - loss: 0.5540 - acc: 0.8548 - val_loss: 0.4226 - val_acc: 0.8775\n",
            "Epoch 14/50\n",
            "3132/3132 [==============================] - 45s 14ms/step - loss: 0.5473 - acc: 0.8553 - val_loss: 0.4210 - val_acc: 0.8735\n",
            "Epoch 15/50\n",
            "3132/3132 [==============================] - 44s 14ms/step - loss: 0.5420 - acc: 0.8550 - val_loss: 0.4177 - val_acc: 0.8819\n",
            "Epoch 16/50\n",
            "3132/3132 [==============================] - 45s 14ms/step - loss: 0.5387 - acc: 0.8550 - val_loss: 0.4144 - val_acc: 0.8819\n",
            "Epoch 17/50\n",
            "3132/3132 [==============================] - 44s 14ms/step - loss: 0.5331 - acc: 0.8551 - val_loss: 0.4125 - val_acc: 0.8810\n",
            "Epoch 18/50\n",
            "3132/3132 [==============================] - 45s 14ms/step - loss: 0.5312 - acc: 0.8561 - val_loss: 0.4025 - val_acc: 0.8750\n",
            "Epoch 19/50\n",
            "3132/3132 [==============================] - 45s 14ms/step - loss: 0.5244 - acc: 0.8557 - val_loss: 0.4013 - val_acc: 0.8775\n",
            "Epoch 20/50\n",
            "3132/3132 [==============================] - 45s 14ms/step - loss: 0.5218 - acc: 0.8558 - val_loss: 0.3964 - val_acc: 0.8765\n",
            "Epoch 21/50\n",
            "3132/3132 [==============================] - 46s 15ms/step - loss: 0.5200 - acc: 0.8564 - val_loss: 0.4041 - val_acc: 0.8765\n",
            "Epoch 22/50\n",
            "3132/3132 [==============================] - 45s 14ms/step - loss: 0.5141 - acc: 0.8562 - val_loss: 0.3990 - val_acc: 0.8814\n",
            "Epoch 23/50\n",
            "3132/3132 [==============================] - 46s 15ms/step - loss: 0.5125 - acc: 0.8560 - val_loss: 0.4018 - val_acc: 0.8745\n",
            "Epoch 24/50\n",
            "3132/3132 [==============================] - 46s 15ms/step - loss: 0.5122 - acc: 0.8573 - val_loss: 0.4065 - val_acc: 0.8755\n",
            "Epoch 25/50\n",
            "3132/3132 [==============================] - 46s 15ms/step - loss: 0.5082 - acc: 0.8567 - val_loss: 0.4018 - val_acc: 0.8720\n",
            "Epoch 26/50\n",
            "3132/3132 [==============================] - 47s 15ms/step - loss: 0.5047 - acc: 0.8569 - val_loss: 0.3969 - val_acc: 0.8735\n",
            "Epoch 27/50\n",
            "3132/3132 [==============================] - 46s 15ms/step - loss: 0.5023 - acc: 0.8577 - val_loss: 0.3976 - val_acc: 0.8725\n",
            "Epoch 28/50\n",
            "3132/3132 [==============================] - 45s 15ms/step - loss: 0.5003 - acc: 0.8576 - val_loss: 0.3967 - val_acc: 0.8795\n",
            "Epoch 29/50\n",
            "3132/3132 [==============================] - 45s 14ms/step - loss: 0.4994 - acc: 0.8574 - val_loss: 0.3881 - val_acc: 0.8819\n",
            "Epoch 30/50\n",
            "3132/3132 [==============================] - 46s 15ms/step - loss: 0.4969 - acc: 0.8573 - val_loss: 0.3930 - val_acc: 0.8770\n",
            "Epoch 31/50\n",
            "3132/3132 [==============================] - 45s 14ms/step - loss: 0.4979 - acc: 0.8580 - val_loss: 0.3947 - val_acc: 0.8790\n",
            "Epoch 32/50\n",
            "3132/3132 [==============================] - 45s 15ms/step - loss: 0.4947 - acc: 0.8575 - val_loss: 0.3951 - val_acc: 0.8795\n",
            "Epoch 33/50\n",
            "3132/3132 [==============================] - 46s 15ms/step - loss: 0.4916 - acc: 0.8586 - val_loss: 0.3973 - val_acc: 0.8730\n",
            "Epoch 34/50\n",
            "3132/3132 [==============================] - 45s 14ms/step - loss: 0.4910 - acc: 0.8583 - val_loss: 0.3899 - val_acc: 0.8800\n",
            "Epoch 35/50\n",
            "3132/3132 [==============================] - 45s 14ms/step - loss: 0.4908 - acc: 0.8590 - val_loss: 0.3941 - val_acc: 0.8725\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SzKBgFQfyS6V",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 437
        },
        "outputId": "5dfeb47e-5f90-49a6-85f3-3d2940b04d52"
      },
      "source": [
        "!tail -n 25 examples.txt"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ein TIE-Fighter des Autoherstellers aus\" aus\" für Android und iOS 10: So setzt Ihr die Anzeige-Modi Watch im\n",
            "================================================================================\n",
            "\n",
            "----- Generating text after Epoch: 34\n",
            "----- Diversity:0.3\n",
            "----- Generating with seed:\n",
            "\"– und\"\n",
            "– und mehr Kraft aus?\\\"\" für Windows Phone 8 und X: Akku lässt sich nicht als Bluetooth-Lautsprecher nutzen\n",
            "----- Diversity:0.4\n",
            "----- Generating with seed:\n",
            "\"– und\"\n",
            "– und mehr Kraft aus?\\\"\" für Android und iOS erschienen\\\"\" Beta für Android und iOS erschienen\\\"\" der neuen\n",
            "----- Diversity:0.5\n",
            "----- Generating with seed:\n",
            "\"– und\"\n",
            "– und mehr Kraft aus?\\\"\" für Android und iOS erschienen\\\"\" Apple Watch Series 4 soll mit größerem Bildschirm\n",
            "----- Diversity:0.6\n",
            "----- Generating with seed:\n",
            "\"– und\"\n",
            "– und mehr Kraft aus?\\\"\" für Android und Windows verfolgen und Co. für Weihnachten ein Pikachu mit X-Mas-Mütze\n",
            "----- Diversity:0.7\n",
            "----- Generating with seed:\n",
            "\"– und\"\n",
            "– und mehr Kraft aus?\\\"\" für Windows Phone 8 aufgetaucht sein noch mehr Apple-Apps für Android und iOS\n",
            "================================================================================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qxoMS75t3_2f",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 454
        },
        "outputId": "6c8b873d-4161-4c66-a30a-f306a00ee494"
      },
      "source": [
        "!ls -l checkpoints"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 4345504\n",
            "-rw-r--r-- 1 root root 177988152 May 12 17:00 lstm-text-gen-epoch001-words10654-sequence2-minfreq1-loss0.9769-acc0.8010-val_loss0.8297-val_acc0.8224\n",
            "-rw-r--r-- 1 root root 177988152 May 12 15:45 lstm-text-gen-epoch001-words10654-sequence2-minfreq1-loss1.9330-acc0.6770-val_loss1.5170-val_acc0.7207\n",
            "-rw-r--r-- 1 root root 177988152 May 12 15:43 lstm-text-gen-epoch001-words10654-sequence2-minfreq1-loss2.6888-acc0.6056-val_loss2.5850-val_acc0.6205\n",
            "-rw-r--r-- 1 root root 177988152 May 12 16:57 lstm-text-gen-epoch001-words10654-sequence2-minfreq1-loss3.4357-acc0.5530-val_loss4.0911-val_acc0.5670\n",
            "-rw-r--r-- 1 root root 177988152 May 12 15:41 lstm-text-gen-epoch001-words10654-sequence2-minfreq1-loss3.4432-acc0.5528-val_loss4.0844-val_acc0.5719\n",
            "-rw-r--r-- 1 root root 177988152 May 12 17:01 lstm-text-gen-epoch002-words10654-sequence2-minfreq1-loss0.8271-acc0.8195-val_loss0.6810-val_acc0.8472\n",
            "-rw-r--r-- 1 root root 177988152 May 12 15:45 lstm-text-gen-epoch002-words10654-sequence2-minfreq1-loss1.3065-acc0.7536-val_loss1.0022-val_acc0.8026\n",
            "-rw-r--r-- 1 root root 177988152 May 12 16:58 lstm-text-gen-epoch002-words10654-sequence2-minfreq1-loss2.6782-acc0.6052-val_loss2.6023-val_acc0.6171\n",
            "-rw-r--r-- 1 root root 177988152 May 12 17:01 lstm-text-gen-epoch003-words10654-sequence2-minfreq1-loss0.7276-acc0.8333-val_loss0.5945-val_acc0.8591\n",
            "-rw-r--r-- 1 root root 177988152 May 12 15:46 lstm-text-gen-epoch003-words10654-sequence2-minfreq1-loss0.9603-acc0.8018-val_loss0.7820-val_acc0.8309\n",
            "-rw-r--r-- 1 root root 177988152 May 12 16:59 lstm-text-gen-epoch003-words10654-sequence2-minfreq1-loss1.9147-acc0.6786-val_loss1.5899-val_acc0.7128\n",
            "-rw-r--r-- 1 root root 177988152 May 12 17:02 lstm-text-gen-epoch004-words10654-sequence2-minfreq1-loss0.6726-acc0.8410-val_loss0.5360-val_acc0.8681\n",
            "-rw-r--r-- 1 root root 177988152 May 12 15:47 lstm-text-gen-epoch004-words10654-sequence2-minfreq1-loss0.7879-acc0.8247-val_loss0.6605-val_acc0.8477\n",
            "-rw-r--r-- 1 root root 177988152 May 12 17:03 lstm-text-gen-epoch005-words10654-sequence2-minfreq1-loss0.6427-acc0.8456-val_loss0.5271-val_acc0.8686\n",
            "-rw-r--r-- 1 root root 177988152 May 12 15:48 lstm-text-gen-epoch005-words10654-sequence2-minfreq1-loss0.7049-acc0.8365-val_loss0.5878-val_acc0.8636\n",
            "-rw-r--r-- 1 root root 177988152 May 12 17:04 lstm-text-gen-epoch006-words10654-sequence2-minfreq1-loss0.6192-acc0.8491-val_loss0.4922-val_acc0.8780\n",
            "-rw-r--r-- 1 root root 177988152 May 12 15:49 lstm-text-gen-epoch006-words10654-sequence2-minfreq1-loss0.6581-acc0.8438-val_loss0.5508-val_acc0.8661\n",
            "-rw-r--r-- 1 root root 177988152 May 12 15:50 lstm-text-gen-epoch008-words10654-sequence2-minfreq1-loss0.6127-acc0.8486-val_loss0.5024-val_acc0.8700\n",
            "-rw-r--r-- 1 root root 177988152 May 12 17:07 lstm-text-gen-epoch010-words10654-sequence2-minfreq1-loss0.5752-acc0.8531-val_loss0.4340-val_acc0.8810\n",
            "-rw-r--r-- 1 root root 177988152 May 12 15:53 lstm-text-gen-epoch012-words10654-sequence2-minfreq1-loss0.5675-acc0.8534-val_loss0.4588-val_acc0.8740\n",
            "-rw-r--r-- 1 root root 177988152 May 12 15:54 lstm-text-gen-epoch013-words10654-sequence2-minfreq1-loss0.5584-acc0.8537-val_loss0.4520-val_acc0.8775\n",
            "-rw-r--r-- 1 root root 177988152 May 12 15:55 lstm-text-gen-epoch014-words10654-sequence2-minfreq1-loss0.5526-acc0.8542-val_loss0.4583-val_acc0.8780\n",
            "-rw-r--r-- 1 root root 177988152 May 12 17:10 lstm-text-gen-epoch015-words10654-sequence2-minfreq1-loss0.5420-acc0.8550-val_loss0.4177-val_acc0.8819\n",
            "-rw-r--r-- 1 root root 177988152 May 12 16:06 lstm-text-gen-epoch029-words10654-sequence2-minfreq1-loss0.5032-acc0.8581-val_loss0.4170-val_acc0.8790\n",
            "-rw-r--r-- 1 root root 177988152 May 12 16:11 lstm-text-gen-epoch036-words10654-sequence2-minfreq1-loss0.4930-acc0.8578-val_loss0.4065-val_acc0.8814\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SfWr1anLyAg5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "model_json = model.to_json()\n",
        "with open(\"lstm-text-gen_acc88.json\", \"w\") as json_file:\n",
        "    json_file.write(model_json)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "enKRdHdR4Xxe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "files.download(\"lstm-text-gen_acc88.json\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cqqJ2N8Z4ceO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save_weights(\"lstm-text-gen_model.h5\")\n",
        "print(\"Saved model to disk\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ITqacKp4vUO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        },
        "outputId": "9bc35dc5-b773-4da0-dbd3-a11e7791e017"
      },
      "source": [
        "!ls -lh"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 57M\n",
            "drwxr-xr-x 2 root root 4.0K May 12 17:10 checkpoints\n",
            "-rw-r--r-- 1 root root  39K May 12 17:26 examples.txt\n",
            "-rw-r--r-- 1 root root 2.3K May 12 17:29 lstm-text-gen_acc88.json\n",
            "-rw-r--r-- 1 root root  57M May 12 17:29 lstm-text-gen_model.h5\n",
            "drwxr-xr-x 1 root root 4.0K May  8 16:22 sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Di0_gQoK4ipu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 437
        },
        "outputId": "f2a6c15f-6e7a-42d1-c7ca-22f4ff646f44"
      },
      "source": [
        "files.download('lstm-text-gen_model.h5')"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------\n",
            "Exception happened during processing of request from ('::ffff:127.0.0.1', 39134, 0, 0)\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.6/socketserver.py\", line 317, in _handle_request_noblock\n",
            "    self.process_request(request, client_address)\n",
            "  File \"/usr/lib/python3.6/socketserver.py\", line 348, in process_request\n",
            "    self.finish_request(request, client_address)\n",
            "  File \"/usr/lib/python3.6/socketserver.py\", line 361, in finish_request\n",
            "    self.RequestHandlerClass(request, client_address, self)\n",
            "  File \"/usr/lib/python3.6/socketserver.py\", line 721, in __init__\n",
            "    self.handle()\n",
            "  File \"/usr/lib/python3.6/http/server.py\", line 418, in handle\n",
            "    self.handle_one_request()\n",
            "  File \"/usr/lib/python3.6/http/server.py\", line 406, in handle_one_request\n",
            "    method()\n",
            "  File \"/usr/lib/python3.6/http/server.py\", line 639, in do_GET\n",
            "    self.copyfile(f, self.wfile)\n",
            "  File \"/usr/lib/python3.6/http/server.py\", line 800, in copyfile\n",
            "    shutil.copyfileobj(source, outputfile)\n",
            "  File \"/usr/lib/python3.6/shutil.py\", line 82, in copyfileobj\n",
            "    fdst.write(buf)\n",
            "  File \"/usr/lib/python3.6/socketserver.py\", line 800, in write\n",
            "    self._sock.sendall(b)\n",
            "ConnectionResetError: [Errno 104] Connection reset by peer\n",
            "----------------------------------------\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y9DD63DjHIj4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "files.download(\"examples.txt\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0jHwkJS-52i-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_text(model, indices_word, word_indices, seed,\n",
        "                  sequence_length, diversity, quantity):\n",
        "    \"\"\"\n",
        "    Similar to lstm_train::on_epoch_end\n",
        "    Used to generate text using a trained model\n",
        "    :param model: the trained Keras model (with model.load)\n",
        "    :param indices_word: a dictionary pointing to the words\n",
        "    :param seed: a string to be used as seed (already validated and padded)\n",
        "    :param sequence_length: how many words are given to the model to generate\n",
        "    :param diversity: is the \"temperature\" of the sample function (usually between 0.1 and 2)\n",
        "    :param quantity: quantity of words to generate\n",
        "    :return: Nothing, for now only writes the text to console\n",
        "    \"\"\"\n",
        "    sentence = seed.split(\" \")\n",
        "    print(\"----- Generating text\")\n",
        "    print('----- Diversity:' + str(diversity))\n",
        "    print('----- Generating with seed:\"' + seed +'\"')\n",
        "\n",
        "    print(seed)\n",
        "    for i in range(quantity):\n",
        "        x_pred = np.zeros((1, sequence_length))\n",
        "        for t, word in enumerate(sentence):\n",
        "            x_pred[0, t] = word_indices[word]\n",
        "\n",
        "        preds = model.predict(x_pred, verbose=0)[0]\n",
        "   \n",
        "        next_index = sample(preds, diversity)\n",
        "        next_word = indices_word[next_index]\n",
        "\n",
        "        sentence = sentence[1:]\n",
        "        sentence.append(next_word)\n",
        "\n",
        "        print(\" \"+next_word, end=\"\")\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FUeQEpvBIu07",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        },
        "outputId": "2736b680-3b16-45cb-b475-35660f916a94"
      },
      "source": [
        "generate_text(model, indices_word, word_indices, \"Neues Samsung\", 2, 0.5, 10)"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----- Generating text\n",
            "----- Diversity:0.5\n",
            "----- Generating with seed:\"Neues Samsung\"\n",
            "Neues Samsung\n",
            " stellt 6-GB-RAM-Chip vor dem Start: Das kann das kleine P8"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}