{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lstm-text-generator.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rawar/tensorflow-notebooks/blob/master/lstm_text_generator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6OYiIvNaLpaQ",
        "colab_type": "text"
      },
      "source": [
        "## Textgenerator based on news\n",
        "\n",
        "Based on Enriques work of an [Word-level LSTM text generator](https://medium.com/coinmonks/word-level-lstm-text-generator-creating-automatic-song-lyrics-with-neural-networks-b8a1617104fb)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fAfKbq7RLj5a",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        },
        "outputId": "ba640ce8-44ce-4bd0-cb54-545d79162013"
      },
      "source": [
        "!pip install tf-nightly-gpu"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tf-nightly-gpu in /usr/local/lib/python3.6/dist-packages (1.14.1.dev20190512)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-gpu) (0.7.1)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-gpu) (0.2.2)\n",
            "Requirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-gpu) (1.16.3)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-gpu) (1.1.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-gpu) (1.11.1)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-gpu) (1.0.7)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-gpu) (0.7.1)\n",
            "Requirement already satisfied: tf-estimator-nightly in /usr/local/lib/python3.6/dist-packages (from tf-nightly-gpu) (1.14.0.dev2019051201)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-gpu) (1.15.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-gpu) (1.0.9)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-gpu) (3.7.1)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-gpu) (0.1.6)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-gpu) (1.12.0)\n",
            "Requirement already satisfied: tb-nightly<1.15.0a0,>=1.14.0a0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-gpu) (1.14.0a20190512)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-gpu) (0.33.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tf-nightly-gpu) (2.8.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tf-nightly-gpu) (41.0.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.15.0a0,>=1.14.0a0->tf-nightly-gpu) (0.15.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.15.0a0,>=1.14.0a0->tf-nightly-gpu) (3.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QGDnESfOL59u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8KV-7cgQL9cC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "url = 'https://gist.githubusercontent.com/rawar/ae4cce269e29c2826163fbca60b544f4/raw/20594a832b44de4b4a5160fb2732399ba09a70e9/reco-content-data.csv'\n",
        "text_corpus = pd.read_csv(url)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "isKcV3P-N1_M",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        },
        "outputId": "b3c58fc0-b112-42ce-d882-77186339b85b"
      },
      "source": [
        "headlines_data_frame = text_corpus['title']\n",
        "headlines_data_frame = headlines_data_frame.dropna()\n",
        "headlines_data_frame.head()"
      ],
      "execution_count": 177,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0                             Google verkauft Motorola\n",
              "1    Touchscreen im Winter: Handy-Handschuhe selber...\n",
              "2    \\Bei WhatsApp als Kontakt blockiert: So merkt ...\n",
              "3    Paper: Facebook stellt neue App im Flipboard-S...\n",
              "4               WhatsApp: mehr Privatsphäre für Nutzer\n",
              "Name: title, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 177
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HjoBmqq6ObR2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "430af8e3-2ef2-4258-d2f1-7f1e5571d07c"
      },
      "source": [
        "#headlins_data_frame.tolist()[0]\n",
        "#text_in_words = [w for w in headlins_data_frame.tolist()[0].split(' ') if w.strip() != '' or w == '\\n']\n",
        "text_in_words = headlins_data_frame.str.split(' ').tolist()\n",
        "#text_in_words = headlins_data_frame.to_csv(None, header=False, index=False).split('\\n')\n",
        "print('Number of sentences:', len(text_in_words))"
      ],
      "execution_count": 178,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of sentences: 15751\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w2SedEtPRKn1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "68b7d923-2614-4d99-e889-aa537b30dbbb"
      },
      "source": [
        "print(text_in_words[15749:15750])"
      ],
      "execution_count": 179,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['Fatburner-Training:', 'Diese', 'Übungen', 'sind', 'für', 'Männer']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S-ahG-H7WWEy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b041f8b6-b5c1-44ff-de1e-264b8a1fd7c8"
      },
      "source": [
        "max_words_per_headline = 5\n",
        "for example in text_in_words:\n",
        "  new_max = len(example)\n",
        "  if new_max > max:\n",
        "    max_words_per_headline = new_max\n",
        "    \n",
        "print(max_words_per_headline)"
      ],
      "execution_count": 229,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "spfLX9jrptps",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "words = set()\n",
        "for sentence in text_in_words:\n",
        "  for word in sentence:\n",
        "    words.add(word)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n0FZGXikqDdg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c0518bce-8dff-4a89-e3f8-efcc612b331e"
      },
      "source": [
        "len(words)"
      ],
      "execution_count": 187,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10654"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 187
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HktnI8lEszSd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "word_indices = dict((c, i) for i, c in enumerate(words))\n",
        "indices_word = dict((i, c) for i, c in enumerate(words))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IwSVSVf6W2rI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "SEQUENCE_LEN = 2\n",
        "MIN_WORD_FREQUENCY = 1\n",
        "STEP = 1\n",
        "BATCH_SIZE = 32"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TFcXCVdfeULj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentences = []\n",
        "next_words = []\n",
        "ignored = 0\n",
        "for sentence in text_in_words:\n",
        "  for i in range(0, len(sentence) - SEQUENCE_LEN, STEP):\n",
        "    sentences.append(sentence[i:i + SEQUENCE_LEN])\n",
        "    next_words.append(sentence[i + SEQUENCE_LEN])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bpV0b6qlgIGA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#print(sentences[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vCA78RmVhIza",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#print(next_words[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QkJgWu4Mggsx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#print(sentences[2])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "69Y8tXc7gm3L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#print(next_words[2])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iE5wwTTLXsT1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def shuffle_and_split_training_set(sentences_original, next_original, percentage_test=2):\n",
        "    # shuffle at unison\n",
        "    print('Shuffling sentences')\n",
        "\n",
        "    tmp_sentences = []\n",
        "    tmp_next_word = []\n",
        "    for i in np.random.permutation(len(sentences_original)):\n",
        "        tmp_sentences.append(sentences_original[i])\n",
        "        tmp_next_word.append(next_original[i])\n",
        "\n",
        "    cut_index = int(len(sentences_original) * (1.-(percentage_test/100.)))\n",
        "    x_train, x_test = tmp_sentences[:cut_index], tmp_sentences[cut_index:]\n",
        "    y_train, y_test = tmp_next_word[:cut_index], tmp_next_word[cut_index:]\n",
        "\n",
        "    print(\"Size of training set = %d\" % len(x_train))\n",
        "    print(\"Size of test set = %d\" % len(y_test))\n",
        "    return (x_train, y_train), (x_test, y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G57ukcEakHaY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "bfc66600-80fd-437d-b1a8-a98c2dcdd578"
      },
      "source": [
        "(sentences_train, next_words_train), (sentences_test, next_words_test) = shuffle_and_split_training_set(sentences, next_words)"
      ],
      "execution_count": 184,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shuffling sentences\n",
            "Size of training set = 98214\n",
            "Size of test set = 2005\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wQUYiObqlsN0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "outputId": "4d33af75-2d52-4906-c946-9bc52a5b1e9f"
      },
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Embedding(input_dim=len(words), output_dim=1024),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(units=128)),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.Dense(len(words)),\n",
        "    tf.keras.layers.Activation('softmax')\n",
        "])"
      ],
      "execution_count": 188,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0512 15:29:23.394547 140615091943296 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/initializers.py:119: calling RandomUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "W0512 15:29:23.398768 140615091943296 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "W0512 15:29:23.414896 140615091943296 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "W0512 15:29:23.416219 140615091943296 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:97: calling Orthogonal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "W0512 15:29:23.423355 140615091943296 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M8KqMMscqgXW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generator(sentence_list, next_word_list, batch_size):\n",
        "    index = 0\n",
        "    while True:\n",
        "        x = np.zeros((batch_size, SEQUENCE_LEN), dtype=np.int32)\n",
        "        y = np.zeros((batch_size), dtype=np.int32)\n",
        "        for i in range(batch_size):\n",
        "            for t, w in enumerate(sentence_list[index % len(sentence_list)]):\n",
        "                x[i, t] = word_indices[w]\n",
        "            y[i] = word_indices[next_word_list[index % len(sentence_list)]]\n",
        "            index = index + 1\n",
        "        yield x, y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dvN-MvovrFep",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss='sparse_categorical_crossentropy', optimizer=\"adam\", metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xP3ek5GpsaxR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir checkpoints"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dkogyqHsrP69",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "file_path = \"./checkpoints/lstm-text-gen-epoch{epoch:03d}-words%d-sequence%d-minfreq%d-\" \\\n",
        "                \"loss{loss:.4f}-acc{acc:.4f}-val_loss{val_loss:.4f}-val_acc{val_acc:.4f}\" % \\\n",
        "                (len(words), SEQUENCE_LEN, MIN_WORD_FREQUENCY)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fBpA9iQjt1vq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sample(preds, temperature=1.0):\n",
        "    # helper function to sample an index from a probability array\n",
        "    preds = np.asarray(preds).astype('float64')\n",
        "    preds = np.log(preds) / temperature\n",
        "    exp_preds = np.exp(preds)\n",
        "    preds = exp_preds / np.sum(exp_preds)\n",
        "    probas = np.random.multinomial(1, preds, 1)\n",
        "    return np.argmax(probas)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G2wXHE9qrWx3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def on_epoch_end(epoch, logs):\n",
        "    # Function invoked at end of each epoch. Prints generated text.\n",
        "    examples_file.write('\\n----- Generating text after Epoch: %d\\n' % epoch)\n",
        "\n",
        "    # Randomly pick a seed sequence\n",
        "    seed_index = np.random.randint(len(sentences+sentences_test))\n",
        "    seed = (sentences+sentences_test)[seed_index]\n",
        "\n",
        "    for diversity in [0.3, 0.4, 0.5, 0.6, 0.7]:\n",
        "        sentence = seed\n",
        "        examples_file.write('----- Diversity:' + str(diversity) + '\\n')\n",
        "        examples_file.write('----- Generating with seed:\\n\"' + ' '.join(sentence) + '\"\\n')\n",
        "        examples_file.write(' '.join(sentence))\n",
        "\n",
        "        for i in range(max_words_per_headline):\n",
        "            x_pred = np.zeros((1, SEQUENCE_LEN))\n",
        "            for t, word in enumerate(sentence):\n",
        "                x_pred[0, t] = word_indices[word]\n",
        "\n",
        "            preds = model.predict(x_pred, verbose=0)[0]\n",
        "            next_index = sample(preds, diversity)\n",
        "            next_word = indices_word[next_index]\n",
        "\n",
        "            sentence = sentence[1:]\n",
        "            sentence.append(next_word)\n",
        "\n",
        "            examples_file.write(\" \"+next_word)\n",
        "        examples_file.write('\\n')\n",
        "    examples_file.write('='*80 + '\\n')\n",
        "    examples_file.flush()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t3EW8J5jreRl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "checkpoint = tf.keras.callbacks.ModelCheckpoint(file_path, monitor='val_acc', save_best_only=True)\n",
        "print_callback = tf.keras.callbacks.LambdaCallback(on_epoch_end=on_epoch_end)\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_acc', patience=20)\n",
        "callbacks_list = [checkpoint, print_callback, early_stopping]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uWiB4lP_tZ8F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "examples_file = open('examples.txt', \"w\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GjRNhXT9r0jp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1915
        },
        "outputId": "11ff3a8d-f7d8-4681-9b66-0fda407cac26"
      },
      "source": [
        "model.fit_generator(generator(sentences, next_words, BATCH_SIZE),\n",
        "                    steps_per_epoch=int(len(sentences)/BATCH_SIZE) + 1,\n",
        "                    epochs=100,\n",
        "                    callbacks=callbacks_list,\n",
        "                    validation_data=generator(sentences_test, next_words_test, BATCH_SIZE),\n",
        "                    validation_steps=int(len(sentences_test)/BATCH_SIZE) + 1)"
      ],
      "execution_count": 210,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "3132/3132 [==============================] - 45s 15ms/step - loss: 1.9330 - acc: 0.6770 - val_loss: 1.5170 - val_acc: 0.7207\n",
            "Epoch 2/100\n",
            "3132/3132 [==============================] - 47s 15ms/step - loss: 1.3065 - acc: 0.7536 - val_loss: 1.0022 - val_acc: 0.8026\n",
            "Epoch 3/100\n",
            "3132/3132 [==============================] - 45s 14ms/step - loss: 0.9603 - acc: 0.8018 - val_loss: 0.7820 - val_acc: 0.8309\n",
            "Epoch 4/100\n",
            "3132/3132 [==============================] - 46s 15ms/step - loss: 0.7879 - acc: 0.8247 - val_loss: 0.6605 - val_acc: 0.8477\n",
            "Epoch 5/100\n",
            "3132/3132 [==============================] - 45s 15ms/step - loss: 0.7049 - acc: 0.8365 - val_loss: 0.5878 - val_acc: 0.8636\n",
            "Epoch 6/100\n",
            "3132/3132 [==============================] - 46s 15ms/step - loss: 0.6581 - acc: 0.8438 - val_loss: 0.5508 - val_acc: 0.8661\n",
            "Epoch 7/100\n",
            "3132/3132 [==============================] - 46s 15ms/step - loss: 0.6276 - acc: 0.8472 - val_loss: 0.5352 - val_acc: 0.8596\n",
            "Epoch 8/100\n",
            "3132/3132 [==============================] - 45s 14ms/step - loss: 0.6127 - acc: 0.8486 - val_loss: 0.5024 - val_acc: 0.8700\n",
            "Epoch 9/100\n",
            "3132/3132 [==============================] - 47s 15ms/step - loss: 0.5979 - acc: 0.8507 - val_loss: 0.4949 - val_acc: 0.8636\n",
            "Epoch 10/100\n",
            "3132/3132 [==============================] - 45s 14ms/step - loss: 0.5859 - acc: 0.8509 - val_loss: 0.4780 - val_acc: 0.8666\n",
            "Epoch 11/100\n",
            "3132/3132 [==============================] - 46s 15ms/step - loss: 0.5753 - acc: 0.8527 - val_loss: 0.4702 - val_acc: 0.8700\n",
            "Epoch 12/100\n",
            "3132/3132 [==============================] - 45s 15ms/step - loss: 0.5675 - acc: 0.8534 - val_loss: 0.4588 - val_acc: 0.8740\n",
            "Epoch 13/100\n",
            "3132/3132 [==============================] - 46s 15ms/step - loss: 0.5584 - acc: 0.8537 - val_loss: 0.4520 - val_acc: 0.8775\n",
            "Epoch 14/100\n",
            "3132/3132 [==============================] - 46s 15ms/step - loss: 0.5526 - acc: 0.8542 - val_loss: 0.4583 - val_acc: 0.8780\n",
            "Epoch 15/100\n",
            "3132/3132 [==============================] - 45s 14ms/step - loss: 0.5452 - acc: 0.8557 - val_loss: 0.4470 - val_acc: 0.8755\n",
            "Epoch 16/100\n",
            "3132/3132 [==============================] - 47s 15ms/step - loss: 0.5445 - acc: 0.8548 - val_loss: 0.4548 - val_acc: 0.8641\n",
            "Epoch 17/100\n",
            "3132/3132 [==============================] - 45s 14ms/step - loss: 0.5391 - acc: 0.8555 - val_loss: 0.4450 - val_acc: 0.8735\n",
            "Epoch 18/100\n",
            "3132/3132 [==============================] - 46s 15ms/step - loss: 0.5356 - acc: 0.8556 - val_loss: 0.4408 - val_acc: 0.8695\n",
            "Epoch 19/100\n",
            "3132/3132 [==============================] - 45s 14ms/step - loss: 0.5320 - acc: 0.8553 - val_loss: 0.4412 - val_acc: 0.8750\n",
            "Epoch 20/100\n",
            "3132/3132 [==============================] - 46s 15ms/step - loss: 0.5255 - acc: 0.8561 - val_loss: 0.4359 - val_acc: 0.8740\n",
            "Epoch 21/100\n",
            "3132/3132 [==============================] - 46s 15ms/step - loss: 0.5254 - acc: 0.8557 - val_loss: 0.4349 - val_acc: 0.8775\n",
            "Epoch 22/100\n",
            "3132/3132 [==============================] - 46s 15ms/step - loss: 0.5204 - acc: 0.8566 - val_loss: 0.4367 - val_acc: 0.8690\n",
            "Epoch 23/100\n",
            "3132/3132 [==============================] - 46s 15ms/step - loss: 0.5139 - acc: 0.8567 - val_loss: 0.4352 - val_acc: 0.8730\n",
            "Epoch 24/100\n",
            "3132/3132 [==============================] - 45s 14ms/step - loss: 0.5149 - acc: 0.8563 - val_loss: 0.4358 - val_acc: 0.8730\n",
            "Epoch 25/100\n",
            "3132/3132 [==============================] - 45s 15ms/step - loss: 0.5119 - acc: 0.8567 - val_loss: 0.4222 - val_acc: 0.8740\n",
            "Epoch 26/100\n",
            "3132/3132 [==============================] - 45s 14ms/step - loss: 0.5106 - acc: 0.8570 - val_loss: 0.4173 - val_acc: 0.8710\n",
            "Epoch 27/100\n",
            "3132/3132 [==============================] - 46s 15ms/step - loss: 0.5068 - acc: 0.8579 - val_loss: 0.4241 - val_acc: 0.8730\n",
            "Epoch 28/100\n",
            "3132/3132 [==============================] - 45s 14ms/step - loss: 0.5062 - acc: 0.8578 - val_loss: 0.4207 - val_acc: 0.8750\n",
            "Epoch 29/100\n",
            "3132/3132 [==============================] - 47s 15ms/step - loss: 0.5032 - acc: 0.8581 - val_loss: 0.4170 - val_acc: 0.8790\n",
            "Epoch 30/100\n",
            "3132/3132 [==============================] - 46s 15ms/step - loss: 0.5036 - acc: 0.8576 - val_loss: 0.4154 - val_acc: 0.8770\n",
            "Epoch 31/100\n",
            "3132/3132 [==============================] - 45s 14ms/step - loss: 0.5042 - acc: 0.8569 - val_loss: 0.4144 - val_acc: 0.8760\n",
            "Epoch 32/100\n",
            "3132/3132 [==============================] - 46s 15ms/step - loss: 0.4982 - acc: 0.8585 - val_loss: 0.4171 - val_acc: 0.8765\n",
            "Epoch 33/100\n",
            "3132/3132 [==============================] - 45s 14ms/step - loss: 0.4965 - acc: 0.8582 - val_loss: 0.4157 - val_acc: 0.8765\n",
            "Epoch 34/100\n",
            "3132/3132 [==============================] - 46s 15ms/step - loss: 0.4973 - acc: 0.8579 - val_loss: 0.4141 - val_acc: 0.8760\n",
            "Epoch 35/100\n",
            "3132/3132 [==============================] - 45s 14ms/step - loss: 0.4969 - acc: 0.8579 - val_loss: 0.4133 - val_acc: 0.8760\n",
            "Epoch 36/100\n",
            "3132/3132 [==============================] - 47s 15ms/step - loss: 0.4930 - acc: 0.8578 - val_loss: 0.4065 - val_acc: 0.8814\n",
            "Epoch 37/100\n",
            "3132/3132 [==============================] - 46s 15ms/step - loss: 0.4900 - acc: 0.8583 - val_loss: 0.4127 - val_acc: 0.8730\n",
            "Epoch 38/100\n",
            "3132/3132 [==============================] - 45s 14ms/step - loss: 0.4932 - acc: 0.8594 - val_loss: 0.4063 - val_acc: 0.8790\n",
            "Epoch 39/100\n",
            "3132/3132 [==============================] - 46s 15ms/step - loss: 0.4903 - acc: 0.8592 - val_loss: 0.4151 - val_acc: 0.8710\n",
            "Epoch 40/100\n",
            "3132/3132 [==============================] - 45s 14ms/step - loss: 0.4904 - acc: 0.8585 - val_loss: 0.4086 - val_acc: 0.8740\n",
            "Epoch 41/100\n",
            "3132/3132 [==============================] - 46s 15ms/step - loss: 0.4887 - acc: 0.8595 - val_loss: 0.3995 - val_acc: 0.8760\n",
            "Epoch 42/100\n",
            "3132/3132 [==============================] - 45s 14ms/step - loss: 0.4850 - acc: 0.8591 - val_loss: 0.4025 - val_acc: 0.8745\n",
            "Epoch 43/100\n",
            "3132/3132 [==============================] - 47s 15ms/step - loss: 0.4876 - acc: 0.8593 - val_loss: 0.4128 - val_acc: 0.8755\n",
            "Epoch 44/100\n",
            "3132/3132 [==============================] - 46s 15ms/step - loss: 0.4823 - acc: 0.8597 - val_loss: 0.4097 - val_acc: 0.8730\n",
            "Epoch 45/100\n",
            "3132/3132 [==============================] - 45s 14ms/step - loss: 0.4852 - acc: 0.8600 - val_loss: 0.4010 - val_acc: 0.8775\n",
            "Epoch 46/100\n",
            "3132/3132 [==============================] - 46s 15ms/step - loss: 0.4823 - acc: 0.8592 - val_loss: 0.4011 - val_acc: 0.8750\n",
            "Epoch 47/100\n",
            "3132/3132 [==============================] - 45s 14ms/step - loss: 0.4833 - acc: 0.8593 - val_loss: 0.4033 - val_acc: 0.8760\n",
            "Epoch 48/100\n",
            "3132/3132 [==============================] - 46s 15ms/step - loss: 0.4804 - acc: 0.8602 - val_loss: 0.4066 - val_acc: 0.8790\n",
            "Epoch 49/100\n",
            "3132/3132 [==============================] - 45s 14ms/step - loss: 0.4823 - acc: 0.8608 - val_loss: 0.3998 - val_acc: 0.8745\n",
            "Epoch 50/100\n",
            "3132/3132 [==============================] - 47s 15ms/step - loss: 0.4827 - acc: 0.8606 - val_loss: 0.4066 - val_acc: 0.8770\n",
            "Epoch 51/100\n",
            "3132/3132 [==============================] - 45s 14ms/step - loss: 0.4822 - acc: 0.8595 - val_loss: 0.3996 - val_acc: 0.8755\n",
            "Epoch 52/100\n",
            "3132/3132 [==============================] - 45s 14ms/step - loss: 0.4800 - acc: 0.8600 - val_loss: 0.3973 - val_acc: 0.8770\n",
            "Epoch 53/100\n",
            "3132/3132 [==============================] - 45s 15ms/step - loss: 0.4775 - acc: 0.8603 - val_loss: 0.3995 - val_acc: 0.8690\n",
            "Epoch 54/100\n",
            "3132/3132 [==============================] - 45s 14ms/step - loss: 0.4813 - acc: 0.8607 - val_loss: 0.4092 - val_acc: 0.8740\n",
            "Epoch 55/100\n",
            "3132/3132 [==============================] - 46s 15ms/step - loss: 0.4787 - acc: 0.8607 - val_loss: 0.4069 - val_acc: 0.8810\n",
            "Epoch 56/100\n",
            "3132/3132 [==============================] - 45s 14ms/step - loss: 0.4774 - acc: 0.8615 - val_loss: 0.4000 - val_acc: 0.8785\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fe2e7691d30>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 210
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SzKBgFQfyS6V",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1011
        },
        "outputId": "04a76808-edcd-4083-fd95-976ae320024c"
      },
      "source": [
        "!less examples.txt"
      ],
      "execution_count": 213,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b7\u001b[?47h\u001b[?1h\u001b=\r\r\n",
            "----- Generating text after Epoch: 0\r\n",
            "----- Diversity:0.3\r\n",
            "----- Generating with seed:\r\n",
            "\"auf YouTube\"\r\n",
            "auf YouTube\r\n",
            "----- Generating text after Epoch: 0\r\n",
            "----- Diversity:0.3\r\n",
            "----- Generating with seed:\r\n",
            "\"Update belohnt\"\r\n",
            "Update belohnt euch bald mit mehr Werbung in den Vordergrund nerven mit Diamant- \bDisplay kommen im Camouflage-Look Das sind die neuen Funktionen für iPhone und A \bpple Watch einer Frau das Leben in Rot erscheinen erscheinen – als mehr Werbung  \bin den Stories nerven nerven für Schulen: Apple stellt AR und Notizen in den\r\n",
            "----- Diversity:0.4\r\n",
            "----- Generating with seed:\r\n",
            "\"Update belohnt\"\r\n",
            "Update belohnt euch bald mit mehr Werbung in den Stories nerven nerven auf dem S \bmartphone: Vulkan und 4 mit mehr Werbung in den Stories nerven nerven für Schule \bn: Apple stellt neues neues Design und mehr Kraft Werbung in den Stories nerven  \bnerven in den Vordergrund nerven geht bei den Stories nerven nerven\r\n",
            "----- Diversity:0.5\r\n",
            "----- Generating with seed:\n",
            "\u001b[K\"Update belohnt\"\n",
            "\u001b[KUpdate belohnt euch bald mit mehr Werbung in den Vordergrund nerven zur Allzweck \b-App Watch einer Frau das Leben in der Netflix-Serie auftauchen\" den Stories ner \bven nerven für Android: So ladet ihr Musik auf iPhone und Apple Watch einer Frau \b das Leben zum Feind\" Eurer Frau das Leben in den Vordergrund nerven [mit\n",
            "----- Diversity:0.6\n",
            "----- Generating with seed:\n",
            "\"Update belohnt\"\n",
            "Update belohnt euch bald mit mehr Werbung in den Vordergrund nerven in der Netfl \bix-Serie auftauchen\" den smarten Assistenten mit Diamant-Display kommen im Camou \bflage-Look Das sind die neuen Funktionen für Windows 10? Das sagt Microsoft Micr \bosoft erhöht S9 Plus sind bald überall mit 256 GB Speicher erhältlich sein wegen \b Händen fürs S9 und\n",
            "----- Diversity:0.7\n",
            "----- Generating with seed:\n",
            "\"Update belohnt\"\n",
            "Update belohnt euch zum schlecht gelaunten Hund erstellen und mehr Kraft Akkulau \bfzeit vor dem MacBook 9 und Bixby 2.0 sollen gleichzeitig erscheinen – aber ohne \b Nintendo Switch gerade so erfolgreich wie Werbung: Zubehör zum Huawei P20 Pro g \bewinnen Auszeichnung für ihr Display an überall mit 256 GB Speicher erhältlich s \bein Greifarm und\n",
            "================================================================================\n",
            "\n",
            "----- Generating text after Epoch: 1\n",
            "\u001b[K----- Diversity:0.3\n",
            "----- Generating with seed:\n",
            "\"JBL Link\"\n",
            "JBL Link 20 ist unser Favorit verändern mit dem MacBook Air 2 und iPad Pro gewin \bnen Auszeichnung für ihr Display erneut 256 GB Speicher erhältlich sein sein Vor \bgänger sein sind bald überall mit 256 GB Speicher erhältlich sein sein Vorgänger \b sein sind bald überall mit 256 GB Speicher erhältlich sein sein Vorgänger\n",
            "----- Diversity:0.4\n",
            "----- Generating with seed:\n",
            "\"JBL Link\"\n",
            "JBL Link 20 ist unser Favorit verändern für iOS: Neue Version und Facebook arbei \bten an neuen Funktionen für alle Smartphones noch diese Woche in Rot erscheinen  \bmit als Bluetooth-Lautsprecher nutzen das Zubehör zum Huawei P20 Pro gewinnen Au \bszeichnung für ihr Display zum Ausklappen? Eurer Spielfigur geplant – Umsatzverl \buste mehr haben mehr Potenzial\n",
            "----- Diversity:0.5\n",
            "----- Generating with seed:\n",
            "\"JBL Link\"\n",
            "JBL Link 20 ist unser Favorit verändern für Schulen: Apple stellt neues neues De \bsign und Co. mal anders: Von Doppelgängern und dreisten Kopien\" in den Vordergru \bnd übertragen – und mehr Kraft wert war bald überall mit 256 GB Speicher erhältl \bich sein sein Xperia C3 vor Dir! Werbung in den Vordergrund übertragen –\n",
            "----- Diversity:0.6\n",
            "\u001b[K----- Generating with seed:\n",
            "\"JBL Link\"\n",
            "JBL Link 20 ist unser Favorit Favorit mit Facebook und Apple Watch einer Frau da \bs Leben in Arbeit sein\" Porträt-Foto nutzen: Das ladet ihr Musik auf iPhone und  \bApple Watch Series 4 soll mit größerem Bildschirm und Akku erscheinen als als iP \bhone und Apple Watch Series 4 soll mit größerem Bildschirm und\n",
            "----- Diversity:0.7\n",
            "----- Generating with seed:\n",
            "\"JBL Link\"\n",
            "JBL Link 300 als Nutzer: Saphirglas vor dem Xperia Z beginnt nächste Woche in Ro \bt erscheinen erscheinen als Zulieferer Filme beschleunigen\" bei Twitter weiterle \bben sich mit Exklusiv-Songs von Konkurrenz absetzen für Kein Home Button – aber  \bohne Nintendo Switch kommt am 19. September beginnen im Test: die Xbox Neue Hinw \beise auf iPhone\n",
            "================================================================================\n",
            "\n",
            "----- Generating text after Epoch: 2\n",
            "----- Diversity:0.3\n",
            "----- Generating with seed:\n",
            "\"Evan Spiegel\"\n",
            "\u001b[Knd Amazon Echo (2017) und Echo Plus im\n",
            "\u001b[K\u001b[?1l\u001b>\u001b[2J\u001b[?47l\u001b8"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qxoMS75t3_2f",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "outputId": "63f8ab63-84d9-4505-cf60-847cadff9d5a"
      },
      "source": [
        "!ls -l checkpoints"
      ],
      "execution_count": 215,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 2433480\n",
            "-rw-r--r-- 1 root root 177988152 May 12 15:45 lstm-text-gen-epoch001-words10654-sequence2-minfreq1-loss1.9330-acc0.6770-val_loss1.5170-val_acc0.7207\n",
            "-rw-r--r-- 1 root root 177988152 May 12 15:43 lstm-text-gen-epoch001-words10654-sequence2-minfreq1-loss2.6888-acc0.6056-val_loss2.5850-val_acc0.6205\n",
            "-rw-r--r-- 1 root root 177988152 May 12 15:41 lstm-text-gen-epoch001-words10654-sequence2-minfreq1-loss3.4432-acc0.5528-val_loss4.0844-val_acc0.5719\n",
            "-rw-r--r-- 1 root root 177988152 May 12 15:45 lstm-text-gen-epoch002-words10654-sequence2-minfreq1-loss1.3065-acc0.7536-val_loss1.0022-val_acc0.8026\n",
            "-rw-r--r-- 1 root root 177988152 May 12 15:46 lstm-text-gen-epoch003-words10654-sequence2-minfreq1-loss0.9603-acc0.8018-val_loss0.7820-val_acc0.8309\n",
            "-rw-r--r-- 1 root root 177988152 May 12 15:47 lstm-text-gen-epoch004-words10654-sequence2-minfreq1-loss0.7879-acc0.8247-val_loss0.6605-val_acc0.8477\n",
            "-rw-r--r-- 1 root root 177988152 May 12 15:48 lstm-text-gen-epoch005-words10654-sequence2-minfreq1-loss0.7049-acc0.8365-val_loss0.5878-val_acc0.8636\n",
            "-rw-r--r-- 1 root root 177988152 May 12 15:49 lstm-text-gen-epoch006-words10654-sequence2-minfreq1-loss0.6581-acc0.8438-val_loss0.5508-val_acc0.8661\n",
            "-rw-r--r-- 1 root root 177988152 May 12 15:50 lstm-text-gen-epoch008-words10654-sequence2-minfreq1-loss0.6127-acc0.8486-val_loss0.5024-val_acc0.8700\n",
            "-rw-r--r-- 1 root root 177988152 May 12 15:53 lstm-text-gen-epoch012-words10654-sequence2-minfreq1-loss0.5675-acc0.8534-val_loss0.4588-val_acc0.8740\n",
            "-rw-r--r-- 1 root root 177988152 May 12 15:54 lstm-text-gen-epoch013-words10654-sequence2-minfreq1-loss0.5584-acc0.8537-val_loss0.4520-val_acc0.8775\n",
            "-rw-r--r-- 1 root root 177988152 May 12 15:55 lstm-text-gen-epoch014-words10654-sequence2-minfreq1-loss0.5526-acc0.8542-val_loss0.4583-val_acc0.8780\n",
            "-rw-r--r-- 1 root root 177988152 May 12 16:06 lstm-text-gen-epoch029-words10654-sequence2-minfreq1-loss0.5032-acc0.8581-val_loss0.4170-val_acc0.8790\n",
            "-rw-r--r-- 1 root root 177988152 May 12 16:11 lstm-text-gen-epoch036-words10654-sequence2-minfreq1-loss0.4930-acc0.8578-val_loss0.4065-val_acc0.8814\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SfWr1anLyAg5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "model_json = model.to_json()\n",
        "with open(\"lstm-text-gen_acc88.json\", \"w\") as json_file:\n",
        "    json_file.write(model_json)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "enKRdHdR4Xxe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "files.download(\"lstm-text-gen_acc88.json\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cqqJ2N8Z4ceO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ad31be44-a486-49e0-b4cf-8dc559b445a1"
      },
      "source": [
        "model.save_weights(\"lstm-text-gen_model.h5\")\n",
        "print(\"Saved model to disk\")"
      ],
      "execution_count": 218,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saved model to disk\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ITqacKp4vUO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        },
        "outputId": "1003378c-54f7-40d7-c6d9-d5dd1f7d7f7e"
      },
      "source": [
        "!ls -lh"
      ],
      "execution_count": 221,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 57M\n",
            "drwxr-xr-x 2 root root 4.0K May 12 16:11 checkpoints\n",
            "-rw-r--r-- 1 root root 118K May 12 16:26 examples.txt\n",
            "-rw-r--r-- 1 root root 2.3K May 12 16:30 lstm-text-gen_acc88.json\n",
            "-rw-r--r-- 1 root root  57M May 12 16:30 lstm-text-gen_model.h5\n",
            "drwxr-xr-x 1 root root 4.0K May  8 16:22 sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Di0_gQoK4ipu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "files.download('lstm-text-gen_model.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0jHwkJS-52i-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0dcc0f21-8e1b-4754-c655-2d1b5535e021"
      },
      "source": [
        "seed_index = np.random.randint(len(sentences+sentences_test))\n",
        "seed = (sentences+sentences_test)[seed_index]\n",
        "word = 'Samsung'\n",
        "for diversity in [0.3, 0.4, 0.5, 0.6, 0.7]:\n",
        "  sentence = seed\n",
        "  for i in range(max_words_per_headline):\n",
        "    x_pred = np.zeros((1, SEQUENCE_LEN))\n",
        "    for t, word in enumerate(sentence):\n",
        "      x_pred[0, t] = word_indices[word]\n",
        "      preds = model.predict(x_pred, verbose=0)[0]\n",
        "      next_index = sample(preds, diversity)\n",
        "      next_word = indices_word[next_index]\n",
        "\n",
        "      sentence = sentence[1:]\n",
        "      sentence.append(next_word)\n",
        "    \n",
        "print(sentence)\n"
      ],
      "execution_count": 241,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['mit', 'Twitter']\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}